<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RTSP to HLS Stream with Face Recognition and OCR</title>
    <script defer src="face-api.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/tesseract.js@latest"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
    <style>
        body {
            margin: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-color: #000;
        }

        #video,
        #overlay {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: contain;
        }

        #overlay {
            pointer-events: none;
        }

        .controls {
            position: absolute;
            bottom: 40px;
            align-items: center;
            display: flex;
            flex-direction: row;
            z-index: 1;
        }

        button {
            margin: 0 10px;
            padding: 10px;
            font-size: 16px;
            background-color: #cdd2d7;
            color: rgb(0, 0, 0);
            border: none;
            border-radius: 50%;
            cursor: pointer;
            transition: background-color 0.3s;
            width: 40px;
            height: 40px;
        }

        button:hover {
            background-color: #0056b3;
        }

        button:active {
            background-color: #004494;
        }

        /* Mobile view adjustments */
        @media (max-width: 600px) {
            .controls {
                flex-direction: row;
                bottom: 50px;
            }

            button {
                margin: 5px 0;
                width: 50px;
                height: 50px;
                font-size: 20px;
            }

            #video,
            #overlay {
                width: 100%;
                height: 100%;
                object-fit: contain;
            }
        }
    </style>
</head>

<body>
    <video id="video" autoplay controls muted></video>
    <canvas id="overlay"></canvas>
    <div class="controls">
        <button onclick="moveCamera('up')">↑</button>
        <button onclick="moveCamera('down')">↓</button>
        <button onclick="moveCamera('left')">←</button>
        <button onclick="moveCamera('right')">→</button>
    </div>
    <script>

        const knownFaceDescriptors = [];
        const detectedPeople = new Set();
        let frameCount = 0;
        let lastFrameData = null;

        async function loadModels() {
            await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
        }

        async function initializePlayer() {
            const video = document.getElementById('video');
            if (Hls.isSupported()) {
                const hls = new Hls();
                hls.loadSource('/proxy/stream.m3u8');
                hls.attachMedia(video);
                hls.on(Hls.Events.MANIFEST_PARSED, function () {
                    video.play();
                    video.playbackRate = 1.25; // Set initial playback speed to 1.25x
                });
                video.addEventListener('loadeddata', async function () {
                    await loadModels();
                    await loadKnownFaces();
                    startFaceRecognition(video);
                });
            }
        }

        async function loadKnownFaces() {
            const personImages = {
                'Akash Masram': ['images/Akash_Masram1.png', 'images/Akash_Masram2.png'],
                'Krunal Choudhary': ['images/Krunal_Choudhary_2.jpg']
            };

            for (const [name, images] of Object.entries(personImages)) {
                const descriptors = [];
                for (const image of images) {
                    const img = await faceapi.fetchImage(image);
                    const detection = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptor();
                    if (detection) {
                        descriptors.push(new Float32Array(detection.descriptor));
                    }
                }
                if (descriptors.length > 0) {
                    knownFaceDescriptors.push(new faceapi.LabeledFaceDescriptors(name, descriptors));
                }
            }
        }

        async function startFaceRecognition(video) {
            const canvas = document.getElementById('overlay');
            const context = canvas.getContext('2d', { willReadFrequently: true });
            const displaySize = { width: video.videoWidth, height: video.videoHeight };
            faceapi.matchDimensions(canvas, displaySize);
            const faceMatcher = new faceapi.FaceMatcher(knownFaceDescriptors, 0.6);

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptors();

                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                context.clearRect(0, 0, canvas.width, canvas.height);

                resizedDetections.forEach(async detection => {
                    const box = detection.detection.box;
                    const descriptor = detection.descriptor;
                    const bestMatch = faceMatcher.findBestMatch(descriptor);
                    const name = bestMatch.label === 'unknown' ? 'Unknown' : bestMatch.label;
                    const text = `${name}`;
                    const drawBox = new faceapi.draw.DrawBox(box, { label: text });
                    drawBox.draw(canvas);

                    context.strokeStyle = '#1f39b8';
                    context.lineWidth = 2;
                    context.strokeRect(box.x, box.y, box.width, box.height);

                    // Send data to backend only if the person is not already detected
                    if (name !== 'Unknown' && !detectedPeople.has(name)) {
                        detectedPeople.add(name); // Add the name to the set
                        try {
                            await axios.post('/storeFaceData', { name: name });
                        } catch (error) {
                            console.error('Error storing face data:', error);
                        }
                    }
                });

                frameCount++;
                if (frameCount % 5 === 0) {
                    if (lastFrameData) {
                        const currentFrameData = context.getImageData(0, 0, canvas.width, canvas.height).data;
                        detectMotion(lastFrameData, currentFrameData);
                    }
                    lastFrameData = context.getImageData(0, 0, canvas.width, canvas.height).data;
                }
            }, 100);
        }

        function detectMotion(lastData, currentData) {
            let motionDetected = false;
            const threshold = 30; // Adjusted sensitivity
            const pixelCount = currentData.length / 4;
            let motionPixels = 0;

            for (let i = 0; i < pixelCount; i++) {
                const rDiff = Math.abs(lastData[i * 4] - currentData[i * 4]);
                const gDiff = Math.abs(lastData[i * 4 + 1] - currentData[i * 4 + 1]);
                const bDiff = Math.abs(lastData[i * 4 + 2] - currentData[i * 4 + 2]);

                if (rDiff > threshold || gDiff > threshold || bDiff > threshold) {
                    motionPixels++;
                }
            }

            if (motionPixels > pixelCount * 0.01) {
                motionDetected = true;
                console.log('Motion detected!');
            }
        }

        function moveCamera(direction) {
            let x = 0;
            let y = 0;

            switch (direction) {
                case 'up':
                    y = 1;
                    break;
                case 'down':
                    y = -1;
                    break;
                case 'left':
                    x = -1;
                    break;
                case 'right':
                    x = 1;
                    break;
            }

            axios.post('/moveCamera', { x, y })
                .then(response => console.log(response.data))
                .catch(error => console.error('Error moving camera:', error));
        }

        window.onload = initializePlayer;

    </script>
</body>

</html>